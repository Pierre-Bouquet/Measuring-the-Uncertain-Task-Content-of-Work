{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebac1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Firm Totals Reference (Global Denominator)...\n",
      "Calculating firm lifespans (Entry/Exit windows)...\n",
      "Loading Seniority Totals Reference (Method 2 Denominator)...\n",
      "\n",
      "Processing File: seniority_1_data.parquet\n",
      "  > 1/5: Preparing Dates and Indices...\n",
      "  > 2/5: Creating Skeleton Grid (2,006,421 firm-task pairs x 57 months)...\n",
      "  > 3/5: Applying Lifespan Filter (Dropping ghosts)...\n",
      "  > 4/5: Merging Task Data (Numerator)...\n",
      "  > 5/5: Merging Firm Totals (Global Denominator)...\n",
      "  > Merging Seniority Totals for Method 2...\n",
      "  > Starting Regressions for 1664 tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regressing Tasks:  23%|██▎       | 388/1664 [01:10<04:26,  4.79it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pyfixest.estimation import fepois\n",
    "from enum import IntEnum\n",
    "\n",
    "# =========================================================================\n",
    "# 0. CONFIGURATION\n",
    "# =========================================================================\n",
    "\n",
    "class ControlMethod(IntEnum):\n",
    "    COMPANY_WIDE = 1        \n",
    "    COMPANY_SENIORITY = 2   \n",
    "\n",
    "# *** SELECT YOUR METHOD HERE ***\n",
    "CONTROL_METHOD = ControlMethod.COMPANY_SENIORITY \n",
    "\n",
    "# DATES\n",
    "PRE_START = '2021-01-01'\n",
    "EXP_END = '2025-09-01'\n",
    "REF_PERIOD = '2022-10-01'\n",
    "\n",
    "# PATHS\n",
    "FILE_PATH = \"./data/seniority_DWA_data_CLEAN/\"\n",
    "RESULTS_DIR = \"./results\"\n",
    "\n",
    "# --- UPDATED PATHS BELOW ---\n",
    "PATH_TO_FIRM_TOTALS = \"./data/firm_level_totals/firm_month_totals.parquet\"\n",
    "PATH_TO_SENIORITY_TOTALS = \"./data/firm_level_totals/firm_seniority_totals.parquet\"\n",
    "# ---------------------------\n",
    "\n",
    "if not os.path.exists(RESULTS_DIR):\n",
    "    os.makedirs(RESULTS_DIR)\n",
    "\n",
    "files_seniority_DWA = sorted(os.listdir(FILE_PATH))\n",
    "date_pattern = re.compile(r\"\\[T\\.(\\d{4}-\\d{2}-\\d{2})\\]\")\n",
    "\n",
    "# =========================================================================\n",
    "# 1. PRE-LOAD GLOBAL DATA\n",
    "# =========================================================================\n",
    "\n",
    "print(\"Loading Firm Totals Reference (Global Denominator)...\")\n",
    "try:\n",
    "    df_totals = pd.read_parquet(PATH_TO_FIRM_TOTALS) \n",
    "    df_totals['month'] = pd.to_datetime(df_totals['month'])\n",
    "    \n",
    "    print(\"Calculating firm lifespans (Entry/Exit windows)...\")\n",
    "    firm_lifespans = df_totals.groupby('firm_id')['month'].agg(['min', 'max']).reset_index()\n",
    "    firm_lifespans.rename(columns={'min': 'firm_start', 'max': 'firm_end'}, inplace=True)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ CRITICAL ERROR: Could not load firm totals from {PATH_TO_FIRM_TOTALS}. {e}\")\n",
    "    raise e\n",
    "\n",
    "# Load Seniority Totals (Only needed if using Method 2)\n",
    "df_seniority_totals = None\n",
    "if os.path.exists(PATH_TO_SENIORITY_TOTALS):\n",
    "    print(\"Loading Seniority Totals Reference (Method 2 Denominator)...\")\n",
    "    df_seniority_totals = pd.read_parquet(PATH_TO_SENIORITY_TOTALS)\n",
    "    df_seniority_totals['month'] = pd.to_datetime(df_seniority_totals['month'])\n",
    "else:\n",
    "    print(f\"⚠️ Warning: Seniority totals file not found at {PATH_TO_SENIORITY_TOTALS}. Method 2 will fail if selected.\")\n",
    "\n",
    "# =========================================================================\n",
    "# 2. SMART BALANCING FUNCTION\n",
    "# =========================================================================\n",
    "\n",
    "def balance_panel_smart(df, df_totals, firm_lifespans):\n",
    "    \"\"\"\n",
    "    Balances the panel ONLY within the active lifespan of each firm.\n",
    "    \"\"\"\n",
    "    print(\"  > 1/5: Preparing Dates and Indices...\")\n",
    "    df['month'] = pd.to_datetime(df['month'])\n",
    "    \n",
    "    unique_firm_tasks = df[['firm_id', 'dwa_id', 'seniority']].drop_duplicates()\n",
    "    all_months = pd.date_range(start=PRE_START, end=EXP_END, freq='MS')\n",
    "    \n",
    "    # Efficient Cross Join\n",
    "    print(f\"  > 2/5: Creating Skeleton Grid ({len(unique_firm_tasks):,} firm-task pairs x {len(all_months)} months)...\")\n",
    "    index = pd.MultiIndex.from_product(\n",
    "        [unique_firm_tasks.index, all_months], \n",
    "        names=['_temp_idx', 'month']\n",
    "    )\n",
    "    skeleton = pd.DataFrame(index=index).reset_index()\n",
    "    skeleton = skeleton.merge(unique_firm_tasks, left_on='_temp_idx', right_index=True).drop(columns=['_temp_idx'])\n",
    "\n",
    "    print(\"  > 3/5: Applying Lifespan Filter (Dropping ghosts)...\")\n",
    "    skeleton = skeleton.merge(firm_lifespans, on='firm_id', how='inner')\n",
    "    skeleton = skeleton[\n",
    "        (skeleton['month'] >= skeleton['firm_start']) & \n",
    "        (skeleton['month'] <= skeleton['firm_end'])\n",
    "    ]\n",
    "    skeleton = skeleton.drop(columns=['firm_start', 'firm_end'])\n",
    "\n",
    "    print(\"  > 4/5: Merging Task Data (Numerator)...\")\n",
    "    balanced = skeleton.merge(\n",
    "        df, \n",
    "        on=['firm_id', 'dwa_id', 'seniority', 'month'], \n",
    "        how='left'\n",
    "    )\n",
    "    balanced['FTE'] = balanced['FTE'].fillna(0)\n",
    "    \n",
    "    print(\"  > 5/5: Merging Firm Totals (Global Denominator)...\")\n",
    "    if 'firm_month_total_fte_all' in balanced.columns:\n",
    "        balanced = balanced.drop(columns=['firm_month_total_fte_all'])\n",
    "        \n",
    "    balanced = balanced.merge(df_totals, on=['firm_id', 'month'], how='left')\n",
    "    balanced = balanced.dropna(subset=['firm_month_total_fte_all'])\n",
    "    \n",
    "    return balanced\n",
    "\n",
    "# =========================================================================\n",
    "# 3. MAIN EXECUTION LOOP\n",
    "# =========================================================================\n",
    "\n",
    "for file_path in files_seniority_DWA:\n",
    "    if not file_path.endswith('.parquet'): continue\n",
    "    \n",
    "    print(f\"\\nProcessing File: {file_path}\")\n",
    "    company_DWA_df = pd.read_parquet(os.path.join(FILE_PATH, file_path))\n",
    "    \n",
    "    # 1. Balance Smartly\n",
    "    balanced_df = balance_panel_smart(company_DWA_df, df_totals, firm_lifespans)\n",
    "    \n",
    "    # 2. Create Controls\n",
    "    balanced_df['month_str'] = balanced_df['month'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # -------------------------------------------------------\n",
    "    # CONTROL METHOD LOGIC (Robust \"Leave-One-Out\")\n",
    "    # -------------------------------------------------------\n",
    "    suffix = \"\"\n",
    "    \n",
    "    if CONTROL_METHOD == ControlMethod.COMPANY_WIDE:\n",
    "        # Control: Log(Total Firm Size - This Task Size + 1)\n",
    "        val = (balanced_df[\"firm_month_total_fte_all\"] - balanced_df[\"FTE\"]).clip(lower=0)\n",
    "        balanced_df[\"Z_control\"] = np.log(val + 1)\n",
    "        suffix = \"_method_company\"\n",
    "        \n",
    "    elif CONTROL_METHOD == ControlMethod.COMPANY_SENIORITY:\n",
    "        if df_seniority_totals is None:\n",
    "            raise ValueError(\"Method 2 selected but 'firm_seniority_totals.parquet' is missing.\")\n",
    "            \n",
    "        print(\"  > Merging Seniority Totals for Method 2...\")\n",
    "        # Merge the TRUE seniority totals (calculated before filtering)\n",
    "        balanced_df = balanced_df.merge(\n",
    "            df_seniority_totals, \n",
    "            on=['firm_id', 'month', 'seniority'], \n",
    "            how='left'\n",
    "        )\n",
    "        # Note: If firm_seniority_total_fte is NaN (rare), it means the firm had 0 people in that seniority tier\n",
    "        balanced_df['firm_seniority_total_fte'] = balanced_df['firm_seniority_total_fte'].fillna(0)\n",
    "\n",
    "        # Control: Log(True Seniority Tier Size - This Task Size + 1)\n",
    "        val = (balanced_df['firm_seniority_total_fte'] - balanced_df['FTE']).clip(lower=0)\n",
    "        balanced_df[\"Z_control\"] = np.log(val + 1)\n",
    "        suffix = \"_method_company_seniority\"\n",
    "    # -------------------------------------------------------\n",
    "    \n",
    "    # 3. Regression Loop\n",
    "    results_list = []\n",
    "    grouped = balanced_df.groupby(['dwa_id', 'seniority'])\n",
    "    \n",
    "    print(f\"  > Starting Regressions for {len(grouped)} tasks...\")\n",
    "    \n",
    "    for (dwa_id, seniority), subset in tqdm(grouped, desc=\"Regressing Tasks\", leave=False):\n",
    "        try:\n",
    "            # Singleton Filter\n",
    "            obs_count = subset.groupby('firm_id').size()\n",
    "            valid_firms = obs_count[obs_count > 1].index\n",
    "            \n",
    "            if len(valid_firms) < 2: continue\n",
    "                \n",
    "            subset_clean = subset[subset['firm_id'].isin(valid_firms)].copy()\n",
    "            \n",
    "            # Remove firms that NEVER perform this task (Separation Check)\n",
    "            # A firm with sum(FTE) = 0 for this task contributes no variance to the FE estimator.\n",
    "            firm_sums = subset_clean.groupby('firm_id')['FTE'].sum()\n",
    "            active_firms = firm_sums[firm_sums > 0].index\n",
    "            subset_clean = subset_clean[subset_clean['firm_id'].isin(active_firms)].copy()\n",
    "\n",
    "            # Final safety check\n",
    "            if subset_clean.empty or subset_clean['FTE'].sum() == 0: \n",
    "                continue\n",
    "\n",
    "            # Run PPML (Poisson Pseudo Maximum Likelihood)\n",
    "            model = fepois(\n",
    "                fml = f\"FTE ~ Z_control + i(month_str, ref='{REF_PERIOD}') | firm_id\",\n",
    "                data = subset_clean,\n",
    "                vcov = {\"CRV1\": \"firm_id\"}\n",
    "            )\n",
    "            \n",
    "            # Extract Results\n",
    "            coefs = model.coef()\n",
    "            se = model.se()\n",
    "            \n",
    "            for name, beta in coefs.items():\n",
    "                match = date_pattern.search(name)\n",
    "                if match:\n",
    "                    results_list.append({\n",
    "                        'dwa_id': dwa_id, \n",
    "                        'seniority': seniority,\n",
    "                        'month': match.group(1),\n",
    "                        'beta': beta,\n",
    "                        'se': se.get(name, 0)\n",
    "                    })\n",
    "            \n",
    "            # Add Ref Period\n",
    "            results_list.append({\n",
    "                'dwa_id': dwa_id, 'seniority': seniority,\n",
    "                'month': REF_PERIOD, 'beta': 0.0, 'se': 0.0\n",
    "            })\n",
    "            \n",
    "        except Exception:\n",
    "            # Skip singular matrix errors silently\n",
    "            pass\n",
    "\n",
    "    # 4. Save Results\n",
    "    if results_list:\n",
    "        res_df = pd.DataFrame(results_list)\n",
    "        \n",
    "        # dynamic filename based on input\n",
    "        # Note: file_path is a string in your loop, so we use os.path.basename\n",
    "        base_name = os.path.basename(file_path).replace('.parquet', '')\n",
    "        out_name = f\"results_{base_name}_{CONTROL_METHOD.name}.csv\"\n",
    "        out_path = os.path.join(RESULTS_DIR, out_name)\n",
    "        \n",
    "        print(f\"✅ Saving {len(res_df)} coefficients to: {out_path}\")\n",
    "        res_df.to_csv(out_path, index=False)\n",
    "    else:\n",
    "        print(f\"⚠️ No results generated for {file_path}\")\n",
    "\n",
    "print(\"\\n*** All Regressions Completed ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4f072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfixest_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
